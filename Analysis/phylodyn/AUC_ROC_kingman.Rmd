---
title: "AUC_ROC_to_kingman"
author: "Shinnosuke Yagi"
date: "2025-10-27"
output: html_document
---

## Method

1. Convert all simulated trees to F-matrix
2. Split the neutral trees into train and test
3. Use train trees to empirically estimate the "Kingman" under neutrality
4. Take distance from the selectice trees and neutral_test trees to the "Kingman"
5. Compare distribution


## Import Libraries

```{r, message=FALSE}
library(ape)
library(spam)
library(devtools)
library(INLA)
library(pROC)
library(ggplot2)
library(dplyr)
library(purrr)
library(readr)
library(stringr)
```

```{r}
install_github("JuliaPalacios/phylodyn")
library(phylodyn)
```

```{r}
#install_github("RSamyak/fmatrix")
library(fmatrix)
```

## Distance Calculation Example

```{r}
# Read a .tree file (Newick format)
tree1 <- read.tree("/Users/yagishinnosuke/Documents/2025-2026 Stanford/Palacios Lab/Selective-Sweep-Simulation/SliM/trees_newick/r3000000.tree")

tree2 <- read.tree("/Users/yagishinnosuke/Documents/2025-2026 Stanford/Palacios Lab/Selective-Sweep-Simulation/SliM/trees_newick/r3060000.tree")

# Check one tree
plot(tree1[[2]], type = "phylogram")
plot(tree2[[2]], type = "phylogram")

dist <- dist_pairwise(tree1[[1]], tree2[[1]], dist.method='l1', weighted=TRUE)
```

## Load all trees from s=0 (set id 0) and s=0.01, freq=0.75 (set id 6)

```{r}
data_dir <- "/Users/yagishinnosuke/Documents/2025-2026 Stanford/Palacios Lab/Selective-Sweep-Simulation/SliM/trees_newick"

# Read .tree FILES by prefix; one list element per file
read_files_by_prefix <- function(dir, prefix) {
  files <- list.files(dir, pattern = paste0("^", prefix, ".*\\.tree$"),
                      full.names = TRUE)
  files <- sort(files)
  out <- lapply(files, function(f) {
    tr <- read.tree(f)                     # phylo or multiPhylo
    if (inherits(tr, "phylo")) {
      # wrap single tree so each element is consistently multiPhylo
      tr <- structure(list(tr), class = "multiPhylo")
    }
    tr
  })
  names(out) <- basename(files)
  out
}

neutrals   <- read_files_by_prefix(data_dir, "r300")
selectives <- read_files_by_prefix(data_dir, "r306")

# Sanity checks
cat("neutrals files:", length(neutrals), "\n")
cat("selectives files:", length(selectives), "\n")

# Example access:
#   first file’s 3rd tree:
#   neutrals[[1]][[3]]
```

# Distribution Comparison

## Load Trees

```{r}
# --- Config ----------------------------------------------------------------
# Directory containing your exported Newick files (one or many trees per file)
data_dir <- "/Users/yagishinnosuke/Documents/2025-2026 Stanford/Palacios Lab/Selective-Sweep-Simulation/SliM/trees_newick"

# Distance settings (pass through to your dist_pairwise)
dist.method <- "l1"
weighted    <- FALSE

# --- Helpers ---------------------------------------------------------------

# Read all files matching a regex pattern; return a named list of 'multiPhylo'
# (If a file has a single tree, we wrap it into a multiPhylo of length 1)
read_files_by_pattern <- function(dir, pattern) {
  files <- list.files(dir, pattern = pattern, full.names = TRUE)
  files <- sort(files)
  out <- lapply(files, function(f) {
    tr <- read.tree(f)                         # phylo or multiPhylo
    if (inherits(tr, "phylo")) {
      tr <- structure(list(tr), class = "multiPhylo")
    }
    tr
  })
  names(out) <- basename(files)
  out
}
```

```{r}
# File-name prefixes that identify the neutral vs selective sets
# (adjust to match how you exported them; these match your earlier example)
neutral_prefix   <- "^r300.*\\.tree$"
selective_prefix <- "^r306.*\\.tree$"

# --- Load data -------------------------------------------------------------
neutrals   <- read_files_by_pattern(data_dir, neutral_prefix)
selectives <- read_files_by_pattern(data_dir, selective_prefix)

cat("Neutral files   :", length(neutrals),   "\n")
cat("Selective files :", length(selectives), "\n")
```

```{r}
neutrals_train <- neutrals[1:50]
neutrals_test <- neutrals[51:100]
```

## Calculate the "empirical Kingman" by taking the mean F-mat of all neutral trees with 49 by 49 dimension
> Use tol=8 to avoid the function treating the tree to have multiple sampling events

```{r}
# neutrals is a list of length = # tree files; each entry is a list/multiPhylo of trees
# (as you noted: access via neutrals[[i]][[j]])
flatten_neutral_trees <- function(neutral_lists) {
  # robustly flatten into a simple list of phylo objects
  out <- list()
  idx <- 1L
  for (i in seq_along(neutral_lists)) {
    trees_i <- neutral_lists[[i]]
    for (j in seq_along(trees_i)) {
      out[[idx]] <- trees_i[[j]]
      attr(out[[idx]], "src_idx") <- c(i = i, j = j)  # keep (i,j) for traceability
      idx <- idx + 1L
    }
  }
  out
}

all_neutral_trees <- flatten_neutral_trees(neutrals_train)
n_trees <- length(all_neutral_trees)
cat(sprintf("Found %d neutral trees.\n", n_trees))

# --- Compute F-matrices with lightweight progress ----------------------------
Fs <- vector("list", n_trees)
pb <- txtProgressBar(min = 0, max = n_trees, style = 3)
for (k in seq_len(n_trees)) {
  Fs[[k]] <- gen_Fmat(all_neutral_trees[[k]], tol=8)  # from tree_distance.R
  setTxtProgressBar(pb, k)
}
close(pb)
```

```{r}
# --- Filter only the F-matrices with dimension 49x49 -------------------------
Fs_valid <- Fs[vapply(Fs, function(m) all(dim(m) == c(49, 49)), logical(1))]

cat(sprintf("Kept %d of %d matrices with 49x49 dimension.\n",
            length(Fs_valid), length(Fs)))

# --- Stack into 3D array and take the element-wise mean ----------------------
F_array <- simplify2array(Fs_valid)
F_empirical_mean <- apply(F_array, c(1, 2), mean)

dimnames(F_empirical_mean) <- dimnames(Fs_valid[[1]])

# --- Done: F_empirical_mean is your empirical “Kingman mean” ------------------
F_empirical_mean[1:min(5, nrow(F_empirical_mean)), 1:min(5, ncol(F_empirical_mean))]
```

## Calculate distance to the "empirical Kingman" for both selective and neutral scenario

```{r}
# Assumptions:
# - F_empirical_mean already exists and is 49x49
# - `neutrals` and `selectives` are your nested lists of trees:
#     neutrals[[i]][[j]] and selectives[[i]][[j]]
# - tree_distance.R is sourced and provides gen_Fmat()

# ---------- helpers ----------
flatten_tree_lists <- function(x) {
  out <- vector("list", 0L)
  idx <- 1L
  for (i in seq_along(x)) {
    xi <- x[[i]]
    for (j in seq_along(xi)) {
      out[[idx]] <- xi[[j]]
      idx <- idx + 1L
    }
  }
  out
}

frob_dist1_unweighted <- function(F1, F2) {
  # L1 (Manhattan) distance without any weighting
  sum(abs(F1 - F2))
}

frob_dist2_unweighted <- function(F1, F2) {
  # L2 (Frobenius) distance without any weighting
  sqrt(sum((F1 - F2)^2))
}

build_Fmats_49 <- function(trees) {
  Fs <- vector("list", length(trees))
  pb <- txtProgressBar(min = 0, max = length(trees), style = 3)
  kept <- logical(length(trees))
  for (k in seq_along(trees)) {
    Fk <- gen_Fmat(trees[[k]], tol=8)
    if (!is.null(Fk) && all(dim(Fk) == c(49, 49))) {
      Fs[[k]] <- Fk
      kept[k] <- TRUE
    }
    setTxtProgressBar(pb, k)
  }
  close(pb)
  Fs[kept]
}

# ---------- build F lists (49x49 only) ----------
cat("Flattening trees...\n")
neu_all <- flatten_tree_lists(neutrals_test)
sel_all <- flatten_tree_lists(selectives)

cat("Building neutral F-matrices (keeping only 49x49)...\n")
Fs_neu_49 <- build_Fmats_49(neu_all)
cat(sprintf("Kept %d neutral F-matrices (49x49).\n", length(Fs_neu_49)))

cat("Building selective F-matrices (keeping only 49x49)...\n")
Fs_sel_49 <- build_Fmats_49(sel_all)
cat(sprintf("Kept %d selective F-matrices (49x49).\n", length(Fs_sel_49)))

# Safety checks
stopifnot(all(dim(F_empirical_mean) == c(49, 49)))
stopifnot(length(Fs_neu_49) > 0L, length(Fs_sel_49) > 0L)
```

```{r}
# ---------- distances to the empirical neutral mean ----------
cat("Computing L1 (unweighted) distances to F_empirical_mean...\n")
d_neutral_l1   <- vapply(Fs_neu_49, function(Fk) frob_dist1_unweighted(Fk, F_empirical_mean), numeric(1))
d_selective_l1 <- vapply(Fs_sel_49, function(Fk) frob_dist1_unweighted(Fk, F_empirical_mean), numeric(1))

# ---------- distances to the empirical neutral mean ----------
cat("Computing L2 (unweighted) distances to F_empirical_mean...\n")
d_neutral_l2   <- vapply(Fs_neu_49, function(Fk) frob_dist2_unweighted(Fk, F_empirical_mean), numeric(1))
d_selective_l2 <- vapply(Fs_sel_49, function(Fk) frob_dist2_unweighted(Fk, F_empirical_mean), numeric(1))
```

## Compare distirbutions to "empirical kingman" under selective and neutral scenarios

### L1-unweighted distance

```{r}
# ---------- plot ----------
df <- rbind(
  data.frame(scenario = "Neutral",   distance = d_neutral_l1),
  data.frame(scenario = "Selective", distance = d_selective_l1)
)

ggplot(df, aes(x = distance, fill = scenario)) +
  geom_density(alpha = 0.35, adjust = 1.0) +
  labs(
    title = "Unweighted L1 distance to empirical neutral F-mean",
    x = "d1 distance",
    y = "Density"
  ) +
  theme_minimal(base_size = 13) +
  theme(legend.position = "top")
```

```{r}
# --- Prepare labels and scores ----------------------------------------------
# Using the distances you already computed:
#   d_neutral   : numeric vector of distances for neutral trees
#   d_selective : numeric vector of distances for selective trees

labels <- c(rep("Neutral",   length(d_neutral_l1)),
            rep("Selective", length(d_selective_l1)))
scores <- c(d_neutral_l1, d_selective_l1)   # higher => more likely Selective

# --- Option A: pROC (simple, robust) ----------------------------------------
if (!requireNamespace("pROC", quietly = TRUE)) install.packages("pROC")

# Positive class = "Selective"; direction ">" means higher score => positive
roc_obj <- roc(response = labels, predictor = scores,
               levels = c("Neutral", "Selective"),
               direction = "<")

auc_val <- as.numeric(auc(roc_obj))

# Build a data frame of ROC points for ggplot
roc_df <- data.frame(
  fpr = 1 - roc_obj$specificities,
  tpr = roc_obj$sensitivities
)

ggplot(roc_df, aes(x = fpr, y = tpr)) +
  geom_path(linewidth = 1.2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray50") +
  coord_equal() +
  labs(
    title = sprintf("ROC curve (AUC = %.3f)", auc_val),
    x = "False Positive Rate (1 - specificity)",
    y = "True Positive Rate (sensitivity)"
  ) +
  theme_minimal(base_size = 13)
```

### L2-unweighted distance

```{r}
# ---------- plot ----------
df <- rbind(
  data.frame(scenario = "Neutral",   distance = d_neutral_l2),
  data.frame(scenario = "Selective", distance = d_selective_l2)
)

ggplot(df, aes(x = distance, fill = scenario)) +
  geom_density(alpha = 0.35, adjust = 1.0) +
  labs(
    title = "Unweighted L2 distance to empirical neutral F-mean",
    x = "d2 (Frobenius) distance",
    y = "Density"
  ) +
  theme_minimal(base_size = 13) +
  theme(legend.position = "top")
```

## Plot ROC_AUC curve

```{r}
# --- Prepare labels and scores ----------------------------------------------
# Using the distances you already computed:
#   d_neutral   : numeric vector of distances for neutral trees
#   d_selective : numeric vector of distances for selective trees

labels <- c(rep("Neutral",   length(d_neutral_l2)),
            rep("Selective", length(d_selective_l2)))
scores <- c(d_neutral_l2, d_selective)   # higher => more likely Selective

# --- Option A: pROC (simple, robust) ----------------------------------------
if (!requireNamespace("pROC", quietly = TRUE)) install.packages("pROC")
library(pROC)

# Positive class = "Selective"; direction ">" means higher score => positive
roc_obj <- roc(response = labels, predictor = scores,
               levels = c("Neutral", "Selective"),
               direction = "<")

auc_val <- as.numeric(auc(roc_obj))

# Build a data frame of ROC points for ggplot
roc_df <- data.frame(
  fpr = 1 - roc_obj$specificities,
  tpr = roc_obj$sensitivities
)

ggplot(roc_df, aes(x = fpr, y = tpr)) +
  geom_path(size = 1.2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray50") +
  coord_equal() +
  labs(
    title = sprintf("ROC curve (AUC = %.3f)", auc_val),
    x = "False Positive Rate (1 - specificity)",
    y = "True Positive Rate (sensitivity)"
  ) +
  theme_minimal(base_size = 13)
```

# Genomic position vs Distance

## Load trees and .csv files for genomic position

```{r}
# --- Paths & settings --------------------------------------------------------
data_dir <- "/Users/yagishinnosuke/Documents/2025-2026 Stanford/Palacios Lab/Selective-Sweep-Simulation/SliM/trees_newick"
break_dir <- data_dir
window_size <- 1000

# load neutral and selective trees (you already have these)
# neutrals, selectives defined earlier
neu_all <- flatten_tree_lists(neutrals_test)
sel_all <- flatten_tree_lists(selectives)

# --- helper: read break CSV corresponding to a .tree file --------------------
read_breaks <- function(file_base) {
  csv_file <- file.path(break_dir, sub("\\.tree$", "_breaks.csv", basename(file_base)))
  read_csv(csv_file, show_col_types = FALSE)
}
```

## Compute distance to "empirical kingman" for trees in each window

```{r}
compute_genomic_distances_from_nested <- function(nested_lists, F_empirical_mean, window_size = 1000) {
  out_all <- list()
  for (f in names(nested_lists)) {
    message("Processing ", f)
    trees_in_file <- nested_lists[[f]]           # multiPhylo
    breaks <- read_breaks(f)

    # F-mats for each tree and 49x49 filter
    Fs <- lapply(seq_along(trees_in_file), function(j) gen_Fmat(trees_in_file[[j]]))
    valid <- vapply(Fs, function(F) !is.null(F) && all(dim(F) == c(49,49)), logical(1))
    Fs <- Fs[valid]
    breaks <- breaks[valid, ]
    if (!length(Fs)) next

    pos <- breaks$mid
    max_pos <- max(breaks$right)
    bins <- seq(0, max_pos, by = window_size)

    df_window <- data.frame(window_mid = bins[-1] - window_size/2, distance = NA_real_)
    for (w in seq_len(nrow(df_window))) {
      left  <- bins[w]; right <- bins[w+1]
      idx <- which(pos >= left & pos < right)
      if (length(idx)) {
        F_mean_win <- Reduce(`+`, Fs[idx]) / length(idx)
        df_window$distance[w] <- frob_dist1_unweighted(F_mean_win, F_empirical_mean)
      }
    }
    df_window$file <- f
    out_all[[f]] <- df_window
  }
  do.call(rbind, out_all)
}

# Use it:
df_neu <- compute_genomic_distances_from_nested(neutrals,   F_empirical_mean, window_size = 1000)
df_sel <- compute_genomic_distances_from_nested(selectives, F_empirical_mean, window_size = 1000)
```

## Plot average distance to "empirical Kingman" against genomic position

```{r}
# --- average across replicates at each genomic position ----------------------
df_neu_avg <- df_neu %>%
  group_by(window_mid) %>%
  summarise(mean_dist = mean(distance, na.rm = TRUE), .groups = "drop") %>%
  mutate(scenario = "Neutral")

df_sel_avg <- df_sel %>%
  group_by(window_mid) %>%
  summarise(mean_dist = mean(distance, na.rm = TRUE), .groups = "drop") %>%
  mutate(scenario = "Selective")

df_all <- bind_rows(df_neu_avg, df_sel_avg)

# --- plot genome scan --------------------------------------------------------
ggplot(df_all, aes(x = window_mid, y = mean_dist, color = scenario)) +
  geom_line(size = 1.1) +
  labs(
    title = "Genome-wide distance to empirical Kingman F-mean",
    x = "Genomic position (bp)",
    y = "Mean L1 distance to empirical neutral F"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top")
```

## Calculate empirical p-value

```{r}
# --- 1. Empirical null from neutral distances -------------------------------
# Sort the neutral distances once
d_neutral_sorted <- sort(d_neutral_l1)
n_neutral <- length(d_neutral_l1)

# --- 2. Define empirical p-value function -----------------------------------
empirical_pval <- function(x, null_sorted) {
  # one-sided upper-tail: P(D_null >= x)
  mean(null_sorted >= x)
}

# --- 3. Compute p-values for selective windows ------------------------------
df_sel$pval <- vapply(df_sel$distance,
                      empirical_pval,
                      numeric(1),
                      null_sorted = d_neutral_sorted)

# Optional: log-transform for clearer visualization
df_sel$log10p <- -log10(df_sel$pval + 1e-10)

# --- Plot genomic position vs empirical p-value (raw scale) -----------------
ggplot(df_sel, aes(x = window_mid, y = pval)) +
  geom_point(color = "#d95f02", linewidth = 1.1) +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "gray50") +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
  labs(
    title = "Empirical significance of selective-tree deviations",
    x = "Genomic position (bp)",
    y = expression(italic(p))
  ) +
  annotate("text", x = Inf, y = 0.05, label = "p = 0.05", hjust = 1.1, vjust = -0.5, size = 3.5) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold")
  )
```

## Estimate Normality, calculate mean and variance from empirical distribution, and calculate p-value

```{r}
# --- Fit Normal to neutral L1 distances -------------------------------------
mu_hat <- mean(d_neutral_l1, na.rm = TRUE)
sd_hat <- sd(d_neutral_l1, na.rm = TRUE)

# sanity: quick normality check (optional)
# qqnorm(d_neutral); qqline(d_neutral, col = "red")  # visual only

# --- One-sided p-values for selective windows (upper tail) -------------------
df_sel$p_norm <- 1 - pnorm(df_sel$distance, mean = mu_hat, sd = sd_hat)

# If you prefer two-sided:
# z <- (df_sel$distance - mu_hat) / sd_hat
# df_sel$p_norm_2sided <- 2 * pmin(pnorm(z), 1 - pnorm(z))

ggplot(df_sel, aes(x = window_mid, y = -log10(p_norm))) +
  geom_point(linewidth = 1.1, color = "#d95f02") +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "gray50") +
  scale_y_continuous(limits = c(0, 10),  # adjust depending on range
                     expand = c(0, 0)) +
  labs(
    title = "Selective windows: Normal-theory significance along genome",
    subtitle = "Higher –log10(p) indicates stronger deviation from neutrality",
    x = "Genomic position (bp)",
    y = expression(-log[10](italic(p)[Normal]))
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(face = "bold"))
```
