---
title: "two_sample_test_reworked"
author: "Shinnosuke Yagi"
date: "2025-05-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(devtools)
install_github("RSamyak/fmatrix")
```

## Load Libraries

```{r, include=FALSE}
library(ape)
library(spam)
library(usethis)
library(devtools)
library(INLA)
library(phytools)
library(devtools)
library(phylodyn)
library(knitr)
library(ggplot2)
library(stringr)
library(jsonlite)
library(dplyr)
library(reticulate)
library(reshape2)
library(tidyr)
```


## Read all tree files and add "state" variable (1 = selective, 0 = neutral) for each locus

```{r}
#all_files <- list.files("/Users/yagishinnosuke/Documents/2024-2025 Stanford/Research/Selective-Sweep-Simulation/Results/Two_Sample_Test_Naive/Ne_10000_L_100000_samples_25_s_0.01_recomb_1.25e-08", pattern = "\\.csv$", full.names = TRUE)

all_files <- list.files("/Users/yagishinnosuke/Documents/2024-2025 Stanford/Research/Selective-Sweep-Simulation/Results/Two_Sample_Test_ARG_0.1/CSVs_run2", pattern = "\\.csv$", full.names = TRUE)

# Parameters
selected_site <- 25000  # Location of selection in bp

for (file in all_files) {
  df <- read.csv(file)
  df <- df %>%
    mutate(state = ifelse(left <= selected_site & right > selected_site, 1, 0))
  
  # Overwrite the same file or save a new one
  write.csv(df, file, row.names = FALSE)
}
```


```{r}
# Initialize empty vector for left positions
all_lefts <- c()

# Loop through each file and extract "left" column
for (file in all_files) {
  df <- read.csv(file)
  all_lefts <- c(all_lefts, df$left)
}

# Get unique and sorted values
finest_grid <- sort(unique(all_lefts))

# Output result
print(finest_grid)
```

## Define functions for the two-sample test

```{r}
# Add padding to F-mat to align dimentions
pad_fmat <- function(mat, target_dim) {
  d <- dim(mat)[1]
  if (d == target_dim) return(mat)
  
  padded <- matrix(0, nrow = target_dim, ncol = target_dim)
  padded[1:d, 1:d] <- mat
  return(padded)
}

#simulates F matrices from BD, uniform or aldous models
#what is the BF distribution?
gen_x <- function(b, m = 100, n = 7, ...){
  x <- rEncod(m = m, n = n, b = b, ...)
  x <- lapply(x, Fmat_from_myencod)
  x <- matrix_list(x)
  x <- t(x)
  x
}

#computes the euclidean distance
dist_x_mu <- function(x,mu){
  diff <- (t(x) - mu)
  distribution <-  apply(diff, 2, function(u){sum(u**2)})
  return(distribution)
}

#Two-sample Kolmogorov-Smirnov statistic, difference between the two empirical distributions
KSstat <- function(x, y){
  ## This portion of code extracted from stat::ks.test
  n.x <- length(x)
  n.y <- length(y)
  w <- c(x, y)
  z <- cumsum(ifelse(order(w) <= n.x, 1/n.x, -1/n.y))

  if (length(unique(w)) < (n.x + n.y)) {
    z <- z[c(which(diff(sort(w)) != 0), n.x + n.y)]
  }

  max(abs(z))
}


cdf<-function(u,x){
  return(sum(x<u)/length(x))
}

KSstat2 <- function(x, y){
  ## This portion of code extracted from stat::ks.test
  n.x <- length(x)
  n.y <- length(y)
  w <- c(x, y)
  u<-unique(sort(w))
  for (i in 1:length(u))
  z<-sapply(1:length(u),function(i){cdf(u[i],x)})-sapply(1:length(u),function(i){cdf(u[i],y)})
  #z <- cumsum(ifelse(order(w) <= n.x, 1/n.x, -1/n.y))
  
  #if (length(unique(w)) < (n.x + n.y)) {
   # z <- z[c(which(diff(sort(w)) != 0), n.x + n.y)]
  #}
  
 return(max(abs(z)))
}
#

pvalue <- function(stat, x, B = 5e3, verbose = TRUE){
  n <- length(x)
  cdf <- rank(x)/n

  freq <- 1/n

  pval <- 0
  if(verbose) cat("simulating brownian bridge processes\n")
  for(i in 1:B){
    if(verbose) cat("\r", i)
    gen <- e1071::rbridge(end = 1, frequency = 1/freq)
    pval <- (i-1)/i*pval + 1/i*(max(abs(gen)) >= stat)
  }
  if(verbose) cat("\ndone!\n")
  return(pval)
}

alt_pvalue<-function(stat,x){
  n <- length(x)
  cdf <- rank(x)/n
  
  freq <- 1/n
  
  pval <- 0
  if(verbose) cat("simulating brownian bridge processes\n")
  for(i in 1:B){
    if(verbose) cat("\r", i)
    gen <- e1071::rbridge(end = 1, frequency = 1/freq)
    pval <- (i-1)/i*pval + 1/i*(max(abs(gen)) >= stat)
  }
}

myHotelling <- function(x, y, ...){
  o1 <- apply(x, 2, sd) == 0
  o2 <- apply(y, 2, sd) == 0
  o3 <- apply(x, 2, mean) == apply(y, 2, mean)

  o <- which(o1 & o2 & o3)

  try({
    ret <- ICSNP::HotellingsT2(x[,-o], y[,-o], ...)$p.value < 0.05
    return(ret)
  })

  return(NA)
}

# Main test function
newTest <- function(x, y, flag = "test", B = 5000, verbose = TRUE){
  n.x <- nrow(x)
  n.y <- nrow(y)

  mu_x <- colMeans(x)
  mu_y <- colMeans(y)

  distxx <- dist_x_mu(x, mu_x)
  distxy <- dist_x_mu(x, mu_y)
  distyx <- dist_x_mu(y, mu_x)
  distyy <- dist_x_mu(y, mu_y)

  STATISTIC <- 0.5 * sqrt(n.x * n.y / (n.x + n.y)) * 
    (KSstat2(distxx, distyx) + KSstat2(distxy, distyy))

  if(flag == "stat") return(STATISTIC)

  w <- rbind(x, y)
  mu_w <- apply(w, 2, mean)
  
  distww <- dist_x_mu(w, mu_w)
  pval <- pvalue(STATISTIC, distww, verbose = FALSE)
  return(list(pval=pval, Statistic=STATISTIC))
}
```

## Two-sample test

Fro each grid loc, extract 100 trees on that loc on each of the 100 chromosomes. Then, two sample test the two distribution.

```{r}
# num_steps <- length(finest_grid) - 1

# Initialize a list to store results
results_list <- list()

# for (i in 1:(length(finest_grid) - 1)) {
  
for (i in 1:19) {
  
  # first_loc <- finest_grid[i]
  # second_loc <- finest_grid[(i + 1)]
  
  first_loc <- i * 5000
  second_loc <- (i + 1) * 5000
  
  # Hold F-matrices for this interval
  fmats_first <- list()
  fmats_second <- list()
  
  for (file in all_files) {
    dt <- read.csv(file)
    
    trees_first <- dt[dt$left <= first_loc & dt$right >= first_loc, ]
    trees_second <- dt[dt$left <= second_loc & dt$right >= second_loc, ]
    
    # Parse and convert each tree to F-matrix
    for (j in 1:nrow(trees_first)) {
      tree <- read.tree(text = trees_first$newick[j])
      fmats_first[[length(fmats_first) + 1]] <- gen_Fmat(tree)
    }
    
    for (j in 1:nrow(trees_second)) {
      tree <- read.tree(text = trees_second$newick[j])
      fmats_second[[length(fmats_second) + 1]] <- gen_Fmat(tree)
    }
  }
  
  all_fmats <- c(fmats_first,fmats_second)
  max_dim <- max(sapply(all_fmats, function(x) dim(x)[1]))
  
  # Apply to both sets
  fmats_first_padded <- lapply(fmats_first, pad_fmat, target_dim = max_dim)
  fmats_second_padded   <- lapply(fmats_second, pad_fmat, target_dim = max_dim)
  
  first_mat <- t(sapply(fmats_first_padded, as.vector))
  second_mat   <- t(sapply(fmats_second_padded, as.vector))
  
  result <- newTest(first_mat, second_mat, verbose = TRUE)
  
  
  # Store in list
  results_list[[i]] <- data.frame(
    first_loc = first_loc,
    second_loc = second_loc,
    p_value = result$pval,
    statistic = result$Statistic
  )
  
  # Print percentage progress
  pct_done <- round(100 * i / num_steps, 1)
  cat(sprintf("\rProgress: %.1f%% (%d/%d)", pct_done, i, num_steps))
  flush.console()
}

# Combine into a single data.frame
results_df <- do.call(rbind, results_list)

head(results_df)
```

```{r}
ggplot(results_df, aes(x = first_loc, y = p_value)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "steelblue") +
  labs(title = "P-values across locations",
       x = "First Location",
       y = "P-value") +
  theme_minimal()
```

```{r}
ggplot(results_df, aes(x = first_loc, y = statistic)) +
  geom_line(color = "darkred", size = 1) +
  geom_point(color = "darkred") +
  geom_vline(xintercept = 25000, color = "red") +
  labs(title = "Test Statistic across locations",
       x = "First Location",
       y = "Statistic") +
  theme_minimal()
```

```{r}
write.csv(results_df, file = "/Users/yagishinnosuke/Documents/2024-2025 Stanford/Research/Selective-Sweep-Simulation/Results/Two_Sample_Test_ARG_0.1/results.csv", row.names = FALSE)
```
